{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dense-buffer",
   "metadata": {},
   "source": [
    "# Análise de texto de fontes desestruturadas e Web\n",
    "\n",
    "## Aula 03\n",
    "\n",
    "Nesta aula iremos trabalhar com extração de informações a partir de imagens (seja JPG ou transformando PDFs) utilizando bibliotecas Python para reconhecimento ótico de caracteres (OCR). A principal biblioteca que utilizaremos será a **EasyOCR** https://github.com/JaidedAI/EasyOCR.\n",
    "\n",
    "\n",
    "## Instalando o EasyOCR\n",
    "\n",
    "Primeiro, vamos instalar a biblioteca que fará a conversão das imagens em texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "overall-ocean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting easyocr\n",
      "  Downloading easyocr-1.7.1-py3-none-any.whl (2.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting Shapely\n",
      "  Downloading shapely-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting ninja\n",
      "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 KB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML in /usr/lib/python3/dist-packages (from easyocr) (5.4.1)\n",
      "Collecting python-bidi\n",
      "  Downloading python_bidi-0.4.2-py2.py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: scipy in /usr/lib/python3/dist-packages (from easyocr) (1.8.0)\n",
      "Requirement already satisfied: Pillow in /usr/lib/python3/dist-packages (from easyocr) (9.0.1)\n",
      "Collecting pyclipper\n",
      "  Downloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (908 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 KB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/gabrielhso/.local/lib/python3.10/site-packages (from easyocr) (1.26.4)\n",
      "Collecting torch\n",
      "  Downloading torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━\u001b[0m \u001b[32m483.1/755.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:53\u001b[0m^C\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━\u001b[0m \u001b[32m483.2/755.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:53\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install easyocr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "insured-entrance",
   "metadata": {},
   "source": [
    "## Instalando o pdf2image\n",
    "\n",
    "Agora, vamos instalar a biblioteca para conversão de PDF em imagem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-sugar",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d18bb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get update\n",
    "!sudo apt-get install libpoppler-dev\n",
    "!sudo apt -y install poppler-utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-selection",
   "metadata": {},
   "source": [
    "## Instalando o ipycanvas\n",
    "\n",
    "Agora, vamos instalar a biblioteca para desenho livre (ver final do notebook):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-estate",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets==7.6.5\n",
    "!pip install ipycanvas==0.11.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indonesian-genesis",
   "metadata": {},
   "source": [
    "## Instalando o opencv\n",
    "\n",
    "Agora, vamos instalar a biblioteca para exibição e desenho nas imagens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-boundary",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install opencv-python==4.5.4.60\n",
    "!pip install --upgrade opencv-contrib-python\n",
    "!pip install opencv-python-headless==4.5.4.60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-pasta",
   "metadata": {},
   "source": [
    "## Importando as bibliotecas necessárias\n",
    "\n",
    "Agora, vamos importar as bibliotecas necessárias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-punishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-incidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canvas hand drawing\n",
    "from ipywidgets import Image\n",
    "from ipywidgets import ColorPicker, IntSlider, link, AppLayout, HBox\n",
    "from ipycanvas import Canvas, hold_canvas\n",
    "\n",
    "# OCR\n",
    "import easyocr\n",
    "\n",
    "# PDF para imagem\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "# para trabalhar com diretórios / sistema operacional\n",
    "import os\n",
    "\n",
    "# para os DataFrames\n",
    "import pandas as pd\n",
    "\n",
    "# para exibir os arquivos de imagem\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-working",
   "metadata": {},
   "source": [
    "Caso obtenha algum erro, utilize o **!pip install** para instalar a biblioteca ausente!\n",
    "\n",
    "Vamos conferir em qual diretório estamos executando o notebook?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-calendar",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"O seu notebook está no diretório\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-badge",
   "metadata": {},
   "source": [
    "## Baixando os dados\n",
    "\n",
    "Se estiver no Colab, utilize este comando para ter acesso às imagens utilizadas durante a aula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-convergence",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget \"https://atd-insper.s3.us-east-2.amazonaws.com/aula03/dados3.zip\"\n",
    "!unzip -P xspabc1 dados3.zip\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-notice",
   "metadata": {},
   "source": [
    "## Um primeiro exemplo!\n",
    "\n",
    "Iremos realizar a leitura dos dados de um documento que está armazenado como uma imagem.\n",
    "\n",
    "Primeiro, vamos indicar o caminho da imagem em uma variável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raising-sound",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_caminho = \"id_uk-driving-licence.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-affair",
   "metadata": {},
   "source": [
    "Iremos exibir a imagem na tela:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-correspondence",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(imagem_caminho)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-assault",
   "metadata": {},
   "source": [
    "Então, utilizaremos um **Reader** do **EasyOCR** para realizar a transcrição dos dados contidos na imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-desktop",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = easyocr.Reader([\"pt\"], gpu=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-running",
   "metadata": {},
   "source": [
    "Para ver mais detalhes sobre a documentação do EasyOCR, acesse https://www.jaided.ai/easyocr/documentation/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-technical",
   "metadata": {},
   "source": [
    "E por fim podemos fazer o reconhecimento dos caracteres com:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-division",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = reader.readtext(imagem_caminho, detail=0)\n",
    "texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-overhead",
   "metadata": {},
   "source": [
    "### Identificação das regiões onde houve reconhecimento de texto\n",
    "\n",
    "Podemos utilizar uma funcionalidade do EasyOCR que permite identificar em quais regiões da imagem houve reconhecimento de caracteres (*bounding boxes*).\n",
    "\n",
    "Para isso, iremos realizar a leitura novamente, mas sem o parâmetro **detail=0**. Neste caso, você pode remover o parâmetro detail ou deixá-lo com valor 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-threshold",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = reader.readtext(imagem_caminho)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-remains",
   "metadata": {},
   "source": [
    "Agora, vamos utilizar o OpenCV para conseguir exibir a imagem, identificando com retângulos as posições onde houve leitura de texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-drill",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(imagem_caminho)\n",
    "\n",
    "for (rec, txt, prob) in texto:\n",
    "    # Coordenadas do retângulo a ser desenhado\n",
    "    (sup_esq, sup_dir, inf_dir, inf_esq) = rec\n",
    "    sup_esq   = (int(sup_esq[0]), int(sup_esq[1]))\n",
    "    inf_dir   = (int(inf_dir[0]), int(inf_dir[1]))\n",
    "    \n",
    "    # Identifica, com um retângulo, as regiões da imagem em que houve leitura de texto\n",
    "    cv2.rectangle(img, sup_esq, inf_dir, (0, 255, 0), 2)\n",
    "    \n",
    "plt.rcParams[\"figure.figsize\"] = (12,12)\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-graph",
   "metadata": {},
   "source": [
    "E então, exibimos os textos reconhecidos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-funds",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(imagem_caminho)\n",
    "\n",
    "for (rec, txt, prob) in texto:\n",
    "    # Coordenadas do retângulo a ser desenhado\n",
    "    (sup_esq, sup_dir, inf_dir, inf_esq) = rec\n",
    "    sup_esq   = (int(sup_esq[0]), int(sup_esq[1]))\n",
    "    inf_dir   = (int(inf_dir[0]), int(inf_dir[1]))\n",
    "    \n",
    "    # Identifica, com um retângulo, as regiões da imagem em que houve leitura de texto\n",
    "    cv2.rectangle(img, sup_esq, inf_dir, (0, 255, 0), 2)\n",
    "    \n",
    "    # Replica, na imagem, os textos identifados\n",
    "    cv2.putText(img, txt, (sup_esq[0], sup_esq[1] - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 200), 2)\n",
    "    \n",
    "plt.rcParams[\"figure.figsize\"] = (12,12)\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-spirit",
   "metadata": {},
   "source": [
    "Alternativa com fundo preto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formed-wound",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(imagem_caminho)\n",
    "\n",
    "for (rec, txt, prob) in texto:\n",
    "    # Coordenadas do retângulo a ser desenhado\n",
    "    (sup_esq, sup_dir, inf_dir, inf_esq) = rec\n",
    "    sup_esq   = (int(sup_esq[0]), int(sup_esq[1]))\n",
    "    inf_dir   = (int(inf_dir[0]), int(inf_dir[1]))\n",
    "    \n",
    "    # Identifica, com um retângulo, as regiões da imagem em que houve leitura de texto\n",
    "    cv2.rectangle(img, sup_esq, inf_dir, (0, 0, 0), -1)\n",
    "    \n",
    "    # Replica, na imagem, os textos identifados\n",
    "    cv2.putText(img, txt, (sup_esq[0], sup_esq[1] + 17), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 200), 2)\n",
    "    \n",
    "plt.rcParams[\"figure.figsize\"] = (12,12)\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-jewel",
   "metadata": {},
   "source": [
    "## Lendo um PDF\n",
    "\n",
    "Para realizar a leitura dos dados, primeiro iremos realizar a sua conversão de PDF para imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998df9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-compensation",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginas = convert_from_path(\"RP_4600023295_NF_1266.pdf\", 500)\n",
    "paginas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-jimmy",
   "metadata": {},
   "source": [
    "Então, podemos salvar cada página como imagem JPG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-resolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "for pg in paginas:\n",
    "    pg.save(\"RP_4600023295_NF_1266_{}.jpg\".format(i), \"JPEG\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-panel",
   "metadata": {},
   "source": [
    "Agora, podemos utilizar a biblioteca **EasyOCR** para efetuar a tradução de **imagem** para **texto**.\n",
    "\n",
    "Observe que já importamos a biblioteca. Agora, iremos utilizar o **Reader** do **EasyOCR** para efetuar o processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-wyoming",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = easyocr.Reader([\"pt\", \"en\"], gpu = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-investigation",
   "metadata": {},
   "source": [
    "Pronto! Com o Reader criado, basta utilizar a função **readtext** passando como parâmetro o caminho até a imagem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-bottom",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = reader.readtext(\"RP_4600023295_NF_1266_1.jpg\")\n",
    "texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-information",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"RP_4600023295_NF_1266_1.jpg\")\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15,15)\n",
    "\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-physiology",
   "metadata": {},
   "source": [
    "## Experimento com livros\n",
    "\n",
    "Iremos recuperar informações de escrita provenientes de livros.\n",
    "\n",
    "Vamos realizar a leitura de apenas uma página de um livro. Considere que o formato já é JPG.\n",
    "\n",
    "Primeiro, exibimos a imagem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"livros_aiwplain1.jpg\")\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15,15)\n",
    "\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-faith",
   "metadata": {},
   "source": [
    "E então podemos fazer o OCR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-sierra",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = easyocr.Reader([\"pt\", \"en\"], gpu = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-strategy",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_texto = reader.readtext(\"livros_aiwplain1.jpg\", detail=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complimentary-republic",
   "metadata": {},
   "source": [
    "Observe que a saída do *readtext* é uma lista, contendo diversos pequenos pedaços (substrings) do texto completo da página. Para transformar esta lista em uma string completa, podemos fazer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-wells",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \" \".join(lista_texto)\n",
    "texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-bernard",
   "metadata": {},
   "source": [
    "Agora poderíamos, por exemplo, procurar um termo no texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-theta",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Alice\" in texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"rabbit\" in texto.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-paradise",
   "metadata": {},
   "source": [
    "Outras alternativas, vistas nas aulas 01 e 02:\n",
    "- Remover pontuações e *stopwords*\n",
    "- Separar em palavras\n",
    "- Contar frequência de palavras\n",
    "- Etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "restricted-swaziland",
   "metadata": {},
   "source": [
    "### Ler vários livros e produzir DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-essex",
   "metadata": {},
   "source": [
    "Considere a lista de páginas de livros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "institutional-stream",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_livros = [\"livros_aiwplain1.jpg\",\n",
    "                \"livros_ipad.jpg\",\n",
    "                \"livros_nlp.jpg\",\n",
    "                \"livros_nlp_2.jpg\",\n",
    "                \"livros_nlp_ods_course.jpg\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-current",
   "metadata": {},
   "source": [
    "**Exercício 1** Crie uma função que recebe um caminho de uma imagem e a exibe na tela. Exiba a imagem de cada um dos livros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-leisure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "severe-given",
   "metadata": {},
   "source": [
    "**Exercício 2** Crie um bloco de código que percorre a lista de livros e utiliza o EasyOCR para efetuar a leitura deles (a partir dos arquivos de imagem).\n",
    "\n",
    "Guarde os textos lidos em um dicionário ou lista, conforme considerar mais fácil e adequado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-alliance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-converter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-whole",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "conservative-father",
   "metadata": {},
   "source": [
    "**Exercício 3** E se quiséssemos descobrir se um trecho de livro contém determinado termo? Crie um bloco de código que permite procurar um termo em determinado livro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-vampire",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "wrong-helmet",
   "metadata": {},
   "source": [
    "**Exercício 4** Agora vamos resumir as nossas descobertas dos blocos anteriores. Considere uma lista de termos para o qual desejamos realizar buscas. Exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-louisville",
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras = [\"mind\", \"presentation\", \"language\", \"summer\", \"natural\", \"rabbit\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-separation",
   "metadata": {},
   "source": [
    "Crie um bloco de código que, a partir dos textos lidos e palavras (termos de busca), produz um DataFrame pandas onde cada linha representa um livro e as colunas representam os termos de busca. Preencha se o termo foi ou não encontrado no livro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-nelson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-reservoir",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-bachelor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-saying",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-circular",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "skilled-childhood",
   "metadata": {},
   "source": [
    "### Exercícios adicionais - Livros\n",
    "\n",
    "**Exercício 5** Faça uma análise visual da qualidade da identificação dos textos contidos nas imagens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-monday",
   "metadata": {},
   "source": [
    "R:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-xerox",
   "metadata": {},
   "source": [
    "**Exercício 6** Extraia as probabilidades para cada termo em cada livro (disponibilizada pelo EasyOCR).\n",
    "\n",
    "a) Identifique estatísticas para cada livro. Probabilidade média, mediana, máxima e mínima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-affiliate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "loose-morgan",
   "metadata": {},
   "source": [
    "b) Para cada livro, exiba a distribuição de probabilidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-hunger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "structural-explorer",
   "metadata": {},
   "source": [
    "## Experimento com notas fiscais\n",
    "\n",
    "Um exemplo prático do uso de OCR poderia envolver a tradução de dados de imagem de notas fiscais para acompanhamento da prestação de contas por instituições públicas.\n",
    "\n",
    "Neste exemplo, vários PDFs que contém representações de notas fiscais eletrônicas foram extraídos do site de prestação de contas do Metrô de São Paulo. Os arquivos são aqueles nomeados no padrão **RP_*.pdf**\n",
    "\n",
    "Links:\n",
    "- https://transparencia.metrosp.com.br/dataset/contrato-rp-4600023295beetrade-assessoria-de-marketing\n",
    "- https://transparencia.metrosp.com.br/dataset/contrato-rp4600023527-bt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-leeds",
   "metadata": {},
   "source": [
    "**Exercício 7** Crie uma função que recebe uma lista de arquivos PDF. Ela deve transformar todos eles para imagem, salvando na mesma pasta, com extensão .jpg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-nashville",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "floppy-allowance",
   "metadata": {},
   "source": [
    "**Exercício 8** Crie um bloco de código que recebe uma lista de imagens, faz o OCR delas e salva um arquivo de mesmo nome, na mesma pasta, com extensão **.txt**. O arquivo de texto deve conter os caracteres reconhecidos na imagem pelo EasyOCR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-quilt",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "neutral-cycling",
   "metadata": {},
   "source": [
    "# Caligrafia\n",
    "\n",
    "Como um experimento, vamos verificar se o EasyOCR consegue identificar caracteres escritos a mão? Para isso, utilizaremos um Canvas com área livre para grafia, com base no pacote **ipycanvas**, disponível em https://ipycanvas.readthedocs.io/en/latest/ ou https://github.com/martinRenou/ipycanvas\n",
    "\n",
    "Primeiro, vamos importar as bibliotecas necessárias. Já fizemos isso no início do notebook, entretanto, deixaremos aqui para fins didáticos, para que percebam bem quais bibliotecas são necessárias em qual parte da aula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-institute",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canvas hand drawing\n",
    "from ipywidgets import Image\n",
    "from ipywidgets import ColorPicker, IntSlider, link, AppLayout, HBox\n",
    "from ipycanvas import Canvas, hold_canvas\n",
    "\n",
    "# OCR\n",
    "import easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121a856a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipycanvas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-tower",
   "metadata": {},
   "source": [
    "Caso algum pacote não tenha sido importado corretamente, utilize o pip para instalar.\n",
    "Por exemplo, para instalar o *ipycanvas*:\n",
    "\n",
    "**!pip install ipycanvas**\n",
    "\n",
    "Agora, vamos configurar alguns parâmetros da área de desenho: altura, largura, cor inicial da caneta de desenho e cor de fundo.\n",
    "\n",
    "Caso queira entender melhor como estamos definindo as cores (padrão RGB em formato hexadecimal), consulte https://www.w3schools.com/Colors/default.asp e https://htmlcolorcodes.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-holly",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 700\n",
    "height = 350\n",
    "\n",
    "stroke_color = \"#0068b3\"\n",
    "background_color = \"#eeeeee\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-accent",
   "metadata": {},
   "source": [
    "e agora, criar a área para desenho. Clique e utilize o mouse para desenhar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd11c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import output\n",
    "output.enable_custom_widget_manager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-gentleman",
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas = Canvas(width=width, height=height)\n",
    "\n",
    "drawing = False\n",
    "position = None\n",
    "shape = []\n",
    "\n",
    "\n",
    "def on_mouse_down(x, y):\n",
    "    global drawing\n",
    "    global position\n",
    "    global shape\n",
    "\n",
    "    drawing = True\n",
    "    position = (x, y)\n",
    "    shape = [position]\n",
    "\n",
    "\n",
    "def on_mouse_move(x, y):\n",
    "    global drawing\n",
    "    global position\n",
    "    global shape\n",
    "\n",
    "    if not drawing:\n",
    "        return\n",
    "\n",
    "    with hold_canvas(canvas):\n",
    "        canvas.stroke_line(position[0], position[1], x, y)\n",
    "        position = (x, y)\n",
    "\n",
    "    shape.append(position)\n",
    "\n",
    "\n",
    "def on_mouse_up(x, y):\n",
    "    global drawing\n",
    "    global position\n",
    "    global shape\n",
    "\n",
    "    drawing = False\n",
    "    \n",
    "    with hold_canvas(canvas):\n",
    "        canvas.stroke_line(position[0], position[1], x, y)\n",
    "        #canvas.fill_polygon(shape)\n",
    "\n",
    "    shape = []\n",
    "\n",
    "\n",
    "canvas.on_mouse_down(on_mouse_down)\n",
    "canvas.on_mouse_move(on_mouse_move)\n",
    "canvas.on_mouse_up(on_mouse_up)\n",
    "\n",
    "canvas.stroke_style = stroke_color\n",
    "\n",
    "canvas.sync_image_data = True\n",
    "\n",
    "canvas.fill_style = background_color\n",
    "canvas.fill_rect(0, 0, canvas.width, canvas.height)\n",
    "\n",
    "picker = ColorPicker(description=\"Color:\", value=stroke_color)\n",
    "\n",
    "link((picker, \"value\"), (canvas, \"stroke_style\"))\n",
    "link((picker, \"value\"), (canvas, \"fill_style\"))\n",
    "\n",
    "HBox((canvas, picker))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "substantial-consistency",
   "metadata": {},
   "source": [
    "Vamos criar um **Reader**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-blogger",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = easyocr.Reader([\"pt\", \"en\"], gpu = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-tooth",
   "metadata": {},
   "source": [
    "Agora, execute a célula abaixo caso queira utilizar o EasyOCR para realizar o OCR da imagem desenhada a mão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d831bbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = \"img1.png\"\n",
    "\n",
    "canvas.to_file(img_name)\n",
    "\n",
    "img = cv2.imread(img_name)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-housing",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader.readtext(img_name, detail = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mobile-german",
   "metadata": {},
   "source": [
    "**Exercício 9** Utilize o canvas e responda os exercícios:\n",
    "\n",
    "a) Desenhe palavras existentes em português. De forma geral, o EasyOCR conseguiu reconhecer corretamente?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-communications",
   "metadata": {},
   "source": [
    "R:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-overall",
   "metadata": {},
   "source": [
    "b) E quando desenhamos palavras inexistentes (mistura aleatória de caracteres)? Justifique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-midnight",
   "metadata": {},
   "source": [
    "R:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-relevance",
   "metadata": {},
   "source": [
    "c) Tente replicar, desenhando a mão, as seguintes escritas:\n",
    "\n",
    "<img src=\"https://atd-insper.s3.us-east-2.amazonaws.com/aula03/handwriting.png\">\n",
    "\n",
    "\n",
    "e compare o desempenho do EasyOCR na identificação dos caracteres das duas imagens. Consegue identificar hipóteses para as diferenças?\n",
    "\n",
    "Obs: o nome da imagem é *handwriting.png*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conditional-number",
   "metadata": {},
   "source": [
    "R:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-proceeding",
   "metadata": {},
   "source": [
    "# Referências\n",
    "\n",
    "Todas as imagens e PDFs utilizados nesta aula foram obtidos em buscadores e encontrados de forma pública na Web.\n",
    "\n",
    "Lista de URLs:\n",
    "\n",
    "Exercício de Livros:\n",
    "- https://scrappystickyinkymess.files.wordpress.com/2013/08/aiwplain1.jpg\n",
    "- http://nlp.ods.asia/Courses/200102.NLP/SLP/slp-preface.pdf\n",
    "- https://static.docsity.com/documents_pages/notas/2015/02/23/9db87522509edf1a679f14c58f421f51.png\n",
    "- https://images-na.ssl-images-amazon.com/images/I/71vlGjCEVyL.jpg\n",
    "- https://help.apple.com/assets/5FF781C3D9C608399A729C42/5FF781C4D9C608399A729C5E/pt_BR/94f62b05596502341b2dd6b73b90fadf.png\n",
    "\n",
    "Notas Fiscais do Metrô SP:\n",
    "- https://transparencia.metrosp.com.br/dataset/contrato-rp-4600023295beetrade-assessoria-de-marketing\n",
    "- https://transparencia.metrosp.com.br/dataset/contrato-rp4600023527-bt\n",
    "\n",
    "ID Cards:\n",
    "- https://s.toptests.co.uk/wp-content/uploads/2017/12/uk-driving-licence.jpg\n",
    "- https://s.driving-tests.org/img/license/alabama-drivers-license.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e902af0",
   "metadata": {},
   "source": [
    "## Extra: `pytesseract`\n",
    "\n",
    "Vamos utilizar uma biblioteca diferente, a `pytesseract` para fazer o reconhecimento de caracteres.\n",
    "\n",
    "Faremos a instalação da aplicação no sistema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349adec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt update\n",
    "!sudo apt install -y tesseract-ocr\n",
    "!sudo apt install -y libtesseract-dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179675b6",
   "metadata": {},
   "source": [
    "A instalação da biblioteca python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2488b129",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fd7929",
   "metadata": {},
   "source": [
    "O import da biblioteca python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57502354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a63619",
   "metadata": {},
   "source": [
    "### Exemplo de uso\n",
    "\n",
    "Vamos abrir a iamgem utilizendo o OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45da5cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_caminho = \"id_uk-driving-licence.jpg\"\n",
    "\n",
    "img = cv2.imread(imagem_caminho)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2c19d4",
   "metadata": {},
   "source": [
    "E utilizar `pytesseract.image_to_string` para fazer a extração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c788d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = pytesseract.image_to_string(img)\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35daee1",
   "metadata": {},
   "source": [
    "Caso queira exibir os bounding boxes, vamos extrair um dicionário com as informações contidas na imagem (texto e mais alguns extras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58b8626",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_c = img.copy()\n",
    "data = pytesseract.image_to_data(img_c, output_type=pytesseract.Output.DICT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6cdac4",
   "metadata": {},
   "source": [
    "Então, vamos exibir os bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10519935",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data[\"level\"])):\n",
    "    if (data[\"text\"][i] != \"\"):\n",
    "        # Extração das coordenadas\n",
    "        (x, y, width, heigth) = (data[\"left\"][i],\n",
    "                                 data[\"top\"][i],\n",
    "                                 data[\"width\"][i],\n",
    "                                 data[\"height\"][i])\n",
    "        # Plot do retângulo nas coordenadas\n",
    "        cv2.rectangle(img_c,\n",
    "                      (x, y),\n",
    "                      (x + width, y + heigth),\n",
    "                      (200, 255, 0),\n",
    "                      2)\n",
    "\n",
    "# Exibe imagem resultante\n",
    "plt.imshow(img_c);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eba4832-5763-4dfc-866a-582f5d674fa8",
   "metadata": {},
   "source": [
    "Por hoje é só!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
