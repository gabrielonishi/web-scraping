{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "comprehensive-turkey",
   "metadata": {},
   "source": [
    "# Análise de texto de fontes desestruturadas e Web\n",
    "\n",
    "## Aula 11\n",
    "\n",
    "Nesta aula vamos fazer uma aplicação prática de Machine Learning.\n",
    "\n",
    "A biblioteca utilizada será a **scikit-learn**.\n",
    "\n",
    "Para conhecer mais sobre ela, acesse https://scikit-learn.org/stable/tutorial/basic/tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da896828",
   "metadata": {},
   "source": [
    "## Baixar os dados no Colab\n",
    "Para baixar os dados no colab, utilize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c6a9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://atd-insper.s3.us-east-2.amazonaws.com/aula10/noticias.csv\n",
    "!wget https://atd-insper.s3.us-east-2.amazonaws.com/aula10/noticias.xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-patrol",
   "metadata": {},
   "source": [
    "## Importando as bibliotecas necessárias\n",
    "\n",
    "Agora, vamos importar as bibliotecas necessárias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-france",
   "metadata": {},
   "outputs": [],
   "source": [
    "# para trabalhar com diretórios / sistema operacional\n",
    "import os\n",
    "\n",
    "# para trabalhar com expressões regulares\n",
    "import re\n",
    "\n",
    "# utilizada para nos indicar o caminho do executável do Python\n",
    "import sys\n",
    "\n",
    "# para pandas DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "# ML\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-regard",
   "metadata": {},
   "source": [
    "Caso obtenha algum erro, utilize o **!pip install** para instalar a biblioteca ausente!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-voluntary",
   "metadata": {},
   "source": [
    "Você pode conferir de onde está executando o Python e qual a versão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-secondary",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Executável:')\n",
    "print(sys.executable)\n",
    "\n",
    "print('\\nVersão do Python:')\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-premium",
   "metadata": {},
   "source": [
    "Vamos conferir em qual diretório iremos trabalhar (é o diretório do notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-quantity",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('O seu notebook está na pasta:')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-chemical",
   "metadata": {},
   "source": [
    "# Text Vectorization\n",
    "\n",
    "Vamos aprender como transformar textos de forma a conseguir treinar modelos a partir deles utilizando o modelo **Bag of Words (BoW)**. No python, o BoW já está implementado como CountVectorizer na biblioteca **sklearn**.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "Considere o dataframe de exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-burst",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Texto\": [\n",
    "            \"quero ir para Praia\",\n",
    "            \"não gosto de praia, só de sol\",\n",
    "            \"quero sombra e água\",\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-suffering",
   "metadata": {},
   "source": [
    "Primeiro, criamos um CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-legislation",
   "metadata": {},
   "outputs": [],
   "source": [
    "exvec = CountVectorizer(binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-grenada",
   "metadata": {},
   "source": [
    "E mandamos ele se *ajustar* aos dados, ou seja, aprender o vocabulário (fit) e já devoltar os dados de treinamento transformados (transform)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-spell",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = exvec.fit_transform(df['Texto']).toarray()\n",
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-block",
   "metadata": {},
   "outputs": [],
   "source": [
    "exvec.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-sight",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vec = pd.DataFrame(mat)\n",
    "df_vec.columns = exvec.get_feature_names_out()\n",
    "df_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-charlotte",
   "metadata": {},
   "source": [
    "### Utilizando com dados novos\n",
    "\n",
    "Agora, podemos utilizar o CountVectorizer com dados novos (frases ainda não vistas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-virginia",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exciting-insert",
   "metadata": {},
   "source": [
    "Primeiro exemplo utilizando uma frase que já pertencia a base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-leather",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = 'quero sombra e água'\n",
    "exvec.transform([txt]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-wrestling",
   "metadata": {},
   "source": [
    "Modificando um pouco a frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-people",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = 'em copacabana quero sombra e água'\n",
    "exvec.transform([txt]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352c0a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = '' # algum texto aqui!\n",
    "exvec.transform([txt]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe85659",
   "metadata": {},
   "outputs": [],
   "source": [
    "exvec.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-commonwealth",
   "metadata": {},
   "source": [
    "Por que ele não modificou?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-thursday",
   "metadata": {},
   "source": [
    "R:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-collective",
   "metadata": {},
   "source": [
    "# Notícias\n",
    "## Carregando os dados\n",
    "\n",
    "Vamos abrir os dados que estão armazenados em planilhas. Você pode escolher a versão CSV ou XLSX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-industry",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('noticias.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-headline",
   "metadata": {},
   "source": [
    "Caso prefira utilizar a versão Excel, abra com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-explanation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('noticias.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-breach",
   "metadata": {},
   "source": [
    "Vamos ver o que temos armazenado no DataFrame?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-regression",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-confidentiality",
   "metadata": {},
   "source": [
    "Quantas notícias temos ao todo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-significance",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-happening",
   "metadata": {},
   "source": [
    "Quantas seções de notícias temos? E quantas notícias por seção?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-india",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Secao'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-harris",
   "metadata": {},
   "source": [
    "# Separando em Treino e Teste\n",
    "\n",
    "Para simular uma situação real de uso do classificador e termos uma ideia de como o classificador se sairá em um uso futuro, iremos dividir nossa base de dados em duas, utilizando uma base para treinar o modelo e outra base para avaliar o desempenho do modelo treinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-junction",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(df[['Titulo', 'Descrição']],\n",
    "                                                            df['Secao'],\n",
    "                                                            test_size=0.25,\n",
    "                                                            random_state=151)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-edgar",
   "metadata": {},
   "source": [
    "Conferindo os dados de treinamento (X e y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-optimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-stationery",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-breath",
   "metadata": {},
   "source": [
    "## Extração de Features\n",
    "\n",
    "Não vamos utilizar direto o título para treino de um modelo. A partir do título, iremos criar variáveis com o uso da técnica de **Bag of Words**.\n",
    "\n",
    "Primeiro, criamos um CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-happening",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "needed-orientation",
   "metadata": {},
   "source": [
    "E *ajustar* ele aos dados, ou seja, fazer aprender o vocabulário (fit) e já devoltar os dados de treinamento transformados (transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-desktop",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = cvec.fit_transform(X_train_raw['Titulo']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-studio",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(mat)\n",
    "X_train.columns = cvec.get_feature_names_out()\n",
    "X_train.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-technique",
   "metadata": {},
   "source": [
    "Agora com os dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-bernard",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-weight",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_test = cvec.transform(X_test_raw['Titulo']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-productivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(mat_test)\n",
    "X_test.columns = cvec.get_feature_names_out()\n",
    "X_test.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-mayor",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-samoa",
   "metadata": {},
   "source": [
    "## Criando o classificador\n",
    "Primeiro, vamos utilizar um **DecisionTreeClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-disclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-hearing",
   "metadata": {},
   "source": [
    "Para treiná-lo, basta fazer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-horizon",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-religion",
   "metadata": {},
   "source": [
    "## Base de testes\n",
    "Agora, vamos ver a performance na base de testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-halifax",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closing-story",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dt.predict(X_test)\n",
    "accuracy_score(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-saturday",
   "metadata": {},
   "source": [
    "## Utilizando Pipeline\n",
    "Agora, vamos ver a performance na base de testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-indicator",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer(binary=True)),\n",
    "        (\"rf\", RandomForestClassifier(n_estimators=100, n_jobs=-1)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train_raw[\"Descrição\"], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-compact",
   "metadata": {},
   "source": [
    "Performance nos dados de treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-courtesy",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_train_raw['Descrição'])\n",
    "accuracy_score(y_true=y_train, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439392b2",
   "metadata": {},
   "source": [
    "Performance nos dados de teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-centre",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test_raw['Descrição'])\n",
    "accuracy_score(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-broadway",
   "metadata": {},
   "source": [
    "# Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-rover",
   "metadata": {},
   "source": [
    "**Exercício 1)** Veja na documentação do `CountVectorizer` o parâmetro `stop_words`. Passe uma lista de palavras para este parâmetro. Explique o que acontece.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "Dica: procure no Google por `nltk stopwords portuguese`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-mineral",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "happy-shipping",
   "metadata": {},
   "source": [
    "R:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-saturday",
   "metadata": {},
   "source": [
    "**Exercício 2)** Veja na documentação do CountVectorizer o parâmetro `vocabulary`. Passe uma lista de palavras para este parâmetro. Explique o que acontece.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-nerve",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "annual-ecology",
   "metadata": {},
   "source": [
    "**Exercício 3)** Veja na documentação do CountVectorizer o parâmetro `binary`. O que acontece se treinarmos um CountVectorizer com `binary=False`? Que impactos, positivos ou negativos, isto pode trazer ao nosso modelo?\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-lewis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7988aab4",
   "metadata": {},
   "source": [
    "**Exercício 4)** Considerando a versão atualizada do seu `CountVectorizer`, verifique a performance de outros modelos. Algumas sugestões:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a95b35e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdc1fe7b",
   "metadata": {},
   "source": [
    "**Exercício 5)** No `CountVectorizer`, consideramos apenas as palavras isoladamente. Entretanto, a ocorrência de certas palavras após outra determinada palavra também é algo informativo. Confira o parâmetro `ngram_range` na documentação do `CountVectorizer`. Teste algumas variações para o `ngram_range` e analise os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4419ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bc4cad3",
   "metadata": {},
   "source": [
    "**Exercício 6)** Existem outras formas de implementar um Vectorizer. Uma opção bastante utilizada é o `tf-idf`.\n",
    "\n",
    "Confira tutoriais em:\n",
    "\n",
    "http://www.tfidf.com\n",
    "\n",
    "https://towardsdatascience.com/natural-language-processing-feature-engineering-using-tf-idf-e8b9d00e7e76\n",
    "\n",
    "E a documentação oficial do sk-lean:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "\n",
    "Então, utilize o `TfidfVectorizer` para vetorização dos testes e avalie sua performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc5183c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21671a13",
   "metadata": {},
   "source": [
    "**Exercício 7)** Os modelos baseados em árvore também podem ser utilizados para seleção de features. Treine um `DecisionTreeClassifier` utilizando uma profundidade baixa (Ex: 4). Desenhe a árvore (aula 09) e confira quais features foram utilizadas para separação das amostras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff47bec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
